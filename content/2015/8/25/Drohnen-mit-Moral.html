+++
title = "Drohnen mit Moral"
date = "2015-08-25T12:08:00"
author = "Dr. Azrael Tod"
tags = ["Nerdig", "Politik", "Pseudoargumente", "Rant", "SÃ¤ue durchs Dorf treiben", "Technik"]
issoid = "blog/1624"
aliases = "blog/1624"
+++

<p>Selbstfahrende Autos, Quadcopter mit Kamera, Kriegsdrohnen, Skynet, das ist die Reihenfolge in der Schwarzseher momentan die technologische Entwicklung sehen.</p>
<p>Das Thema wird dann immer von "Experten" mit so unglaublich vielen unertr&auml;glichen Missverst&auml;ndnissen und mit Bl&ouml;dsinn aufgeladen, dass meine Stirn bei dem Thema schon aus Gewohnheit gr&uuml;n und blau wird, bevor ich &uuml;berhaupt zu einem Tisch oder einer Wand laufen kann.</p>
<p></p><blockquote>Was passiert bei Programmierfehlern bei Drohnen? Wenn so eine autonome Maschine einen Mensch t&ouml;tet, haftet dann der Programmierer?</blockquote><br/>Ein sehr lange gel&ouml;stes Problem - Was passiert heute wenn eine Fabrik explodiert, ein Flugzeug aufgrund technischem Defekes abst&uuml;rzt oder jemand von einem schlecht erzogenem Hund angefallen wird?<br/><blockquote>Die KI kommt und k&ouml;nnte die Menschheit verdr&auml;ngen</blockquote><br/>Nein, einfach nein.<br/><blockquote>Wir brauchen programmierte Ethik. Stellen Sie sich vor ein selbstfahrender PKW muss entscheiden ob er ein auf einen anderes Auto auffahren oder auf den Fu&szlig;weg ausweichen und Fu&szlig;g&auml;nger t&ouml;ten soll! Auch wenn die Automatik hier keine Vorstellung von Ethik haben w&uuml;rde, muss der Programmierer seine Ethik implementieren.</blockquote><br/>Bl&ouml;dsinn! So funktioniert sowas einfach nicht.<br/>Analog zu dieser "Problemstellung" w&auml;re z.B. wenn wir eine automatische Stanze in einer Fabrik stehen haben, und wir bauen Sensoren ein die erkennen wo der Bediener gerade die H&auml;nde hat um dann lieber auf die Linke Hand zu schlagen, weil die entbehrlicher ist.

<p>Wenn ein Auto nicht kontrollieren kann ob es mit irgendwas kollidiert, muss es anhalten! Es darf schlicht nicht schneller fahren als es Hindernisse mit Sensoren rechtzeitig erkennen kann. Wenn das nicht gew&auml;hrleistet werden kann, dann ist das ein Fehler. Dann gilt wieder die gleiche Problematik wie bei jeder anderen, defekten Maschine.</p>
<p>Ein korrekt funktionierender Roboter &uuml;bersch&auml;tzt seine F&auml;higkeiten halt nicht und f&auml;hrt zu schnell. Das ist ja kein Mensch.</p>
<p></p><blockquote>Aber was wenn die Stra&szlig;e pl&ouml;tzlich vereist, spielende Kinder auf die Stra&szlig;e springen und andere unvorhersehbare Umst&auml;nde so eine ethische Entscheidung erzwingen?</blockquote><br/>Auch dann gibt es keine Routine die entscheidet "ein Kind ist mehr Wert als ein Erwachsener". Wenn die Kiste nicht rechtzeitig bremsen kann und ausweichen muss, kann sie versuchen auszuweichen. Sensoren k&ouml;nnen evtl. erkennen dass in einer bestimmten Richtung kein Hindernis ist und dann wird dahin ausgewichen.

<p>Aber zu erkennen was da f&uuml;r Hindernisse rumstehen, wie wichtig/entbehrlich welches ist und welcher Schaden entstehen w&uuml;rde, wenn man damit kollidiert, das sind halt so unglaublich komplexe Vorg&auml;nge, dass die reine Grundidee sowas zu erw&auml;gen v&ouml;llig idiotisch ist.<br/>In einer solchen, von au&szlig;en erzwungenen Situation wird das Programm einfach scheitern.</p>
<p>Ist das schlimm? Nein! Zu scheitern wenn es keine andere M&ouml;glichkeit gibt kann ich beim besten Willen nicht als ein Problem auf Seite des Programmes ansehen. Ja, vlt. k&ouml;nnte man "besser" scheitern, vlt. k&ouml;nnte man Schaden minimieren, aber Tatsache bleibt dass da bereits lange vorher etwas falsch gehandhabt wurde. Offensichtlich war ja die Geschwindigkeit zu hoch.<br/>Und &uuml;berhaupt... was solls? Es ist ja nicht so als w&uuml;rde ein Mensch sowas in Sekundenbruchteilen sinnvoll abw&auml;gen k&ouml;nnen oder als h&auml;tte menschliche Steuerung in diesem Fall irgendeinen Vorteil.</p>
<p>Der einzige Punkt der hier gegen eine Computersteuerung spricht bleibt jener r&uuml;ckst&auml;ndige Idiot der einen imagin&auml;ren Kontrollverlust bef&uuml;rchtet.<br/>Frei nach dem Motto: "Lieber jedes Jahr tausende Leute sich selber mit ihrem Auto umbringen lassen, als 100 Leute pro Jahr ohne Eigenverschulden bei einem Flugzeugabsturz ums Leben kommen lassen.</p>
<p>Denn wir alle wissen ja dass wirklich schlimme Unf&auml;lle nur schlechten Fahrern passieren und wir alle sind &uuml;berdurchschnittlich gut!<br/>Der Unfall den ich hatte? Ach das war eine Sondersituation, da war ich betrunken oder hatte Sekundenschlaf, oder musste Niesen. Sowas passiert halt...</p>
<p></p><blockquote>Aber was wenn eine Drohne auf ein AKW abst&uuml;rzt?</blockquote><br/>Oh.. mal andere, ebenfalls ganz schlimme Katastrophenideen!

<p>Von was f&uuml;r einer Drohne reden wir? Eine kleine, (Paketliefer-)Drohne von denen wir annehmen dass sie demn&auml;chst in Schw&auml;rmen &uuml;berall rumschwirren? Na das wird das AKW doch hoffentlich aushalten!<br/>Irgendwas mit mehr als 20kg Traglast? F&uuml;r das gelten halt die gleichen Regeln wie f&uuml;r Flugzeuge. Was ist wenn ein Flugzeug aufs AKW knallt?</p>
<p>Das AKW geht trotzdem durch sowas kaputt? Vlt. lag das Problem dann ja nicht an der Drohne, sondern am (falsch konstruierten) AKW? Warum fliegst du &uuml;berhaupt mit deiner Drohne &uuml;ber dem AKW rum?</p>
<p>Im Gegenteil: bei Drohnen wird sich (im Gegensatz zu bemannten Flugk&ouml;rpern) nicht mal jemand aufregen wenn man die beim Eintreten in verbotene Gebiete einfach abschie&szlig;t. Das Problem wird also LEICHTER zu l&ouml;sen statt schwerer.</p>
<p></p><blockquote>Aber Fu&szlig;g&auml;nger! Was wenn die Drohne auf den Fu&szlig;g&auml;nger f&auml;llt?</blockquote><br/>Was wenn mein Blumentopf vom Balkon und auf einen Fu&szlig;g&auml;nger f&auml;llt, weil das technische System das das verhindern soll (Balken/Schnur) versagt?
      
    
  